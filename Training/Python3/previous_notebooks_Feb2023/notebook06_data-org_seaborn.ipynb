{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UMD FIRE Stream- Genome Computing VI\n",
    "## Genome Computing-specific data & Distributions\n",
    "### Introduction to `seaborn`\n",
    "\n",
    "Here we will fine-tune tool usage for Genome Computing specific tasks and introduce methods from the `seaborn` and `sklearn` modules.\n",
    "\n",
    "In this notebook we will learn:\n",
    "<ul>\n",
    "    <li>parse and organize data</li>\n",
    "    <li>figure data best practices</li>\n",
    "    <li>making distribution plots with `seaborn`</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Genome Computing: Parameter File Construction\n",
    "### From sequence and standard rest state\n",
    "\n",
    "Parameter files are critical in our structural work. Rather than build 3D structures using all-atom .pdb files, we can make approximations about the kind of DNA to model after, such as the biologically-dominant B-DNA form. This means that the base pairs can be approximated as regular rectangular planes.\n",
    "\n",
    "Thus, to make a 100-bp chain of DNA, rather than making a file of ~ 100-bp*(2 chains)*(30 atoms)*(3 Cartesian coordinates), all we need are the rigid-body base-pair step parameters, which is 100-bp*(6 parameters). A much smaller file.\n",
    "\n",
    "Analysis of experimental findings has given us a sense of sequence specific effects. Here we will make a 125-bp structure of a random DNA sequence using one such sequence-specific data (see: Olson, et al, PNAS 1998)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, import packages\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, set up any variables, lists, and dictionaries that may be used through this section.\n",
    "# Pre-loading such items at the beginning of code is a great practice, especially if a goal would be to turn a notebook into a python script\n",
    "\n",
    "bases     = ['A','T','C','G']\n",
    "basepairs = {'A':'A-T', 'T':'T-A', 'C':'C-G', 'G':'G-C'}\n",
    "\n",
    "\n",
    "# Check to see if list and dictionary works. Remove the comment-out symbols below and execute codeblock\n",
    "#N_seq = 125\n",
    "#seq   = ''.join(np.random.choice(bases) for i in range(N_seq))\n",
    "#print(seq)\n",
    "#for i in range(len(seq)):\n",
    "#    print(basepairs[ seq[i] ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The pre-loading portion should include your standard rest-state model.\n",
    "# This is a formatted text file, so we should reorganize our data to be easier in interact with\n",
    "\n",
    "# I have commented out several \"read_csv\" keyboards that will add in our reorganization\n",
    "# --- remove each comment to get a better sense of what they do\n",
    "# --- or visit the read_csv() documentation here: https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html\n",
    "\n",
    "stds = pd.read_csv(\"datafiles/stepparameters_olson1998.txt\", \n",
    "                   names=['dimer','tilt','roll','twist','shift','slide','rise'],\n",
    "                   #engine=\"python\",\n",
    "                   #index_col=\"dimer\", \n",
    "                   #delimiter=',|={',  \n",
    "                  )\n",
    "\n",
    "# -!- Fix the rise column\n",
    "#stds.rise = stds.rise.str.replace('}','', regex=True).astype(float)\n",
    "stds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data in this file is organized by <b>dimer sequence</b>.\n",
    "\n",
    "Rather than the 4 base pairs (A, G, T, C), there are 4<sup>2</sup> or 16 base-pair steps.\n",
    "This gives us a lot of information to work with, study, and generate models around.\n",
    "\n",
    "We need to make a new dataframe and populate with data from our rest state based on our random DNA sequence above.\n",
    "\n",
    "The key will be programmatically getting the dimer we want from the string, accessing our rest state, and copying that data to our dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make an empty dataframe with a length that matches the length of the DNA sequence\n",
    "# Make sure you use the same base-pair step parameter headers as the one from the rest state file\n",
    "\n",
    "maindf = pd.DataFrame(columns=['#'] + stds.columns.values.tolist(),\n",
    "                      index=[i for i in range(len(      ))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next we will use a series of for and if loops to populate the dataframe from the rest state\n",
    "\n",
    "# --- FILL IN THE  \"<___>\" MISSING CODE\n",
    "\n",
    "for i in range(len( <___> )):\n",
    "    # Insert the base pair \n",
    "    maindf.at[i, '#'] = basepairs[ seq[i] ]\n",
    "    \n",
    "    # loop over the six parameters from the rest state file\n",
    "    for PAR in ['tilt','roll','twist','shift','slide','rise']: \n",
    "        # Recall that since these are base-pair STEP parameters, these must be zero in the first row\n",
    "        if i == 0:\n",
    "            maindf.at[i, <___> ] = 0.000\n",
    "        \n",
    "        # Add the DIMER value from the rest state into this line\n",
    "        else:\n",
    "            maindf.at[i, PAR] = <___>.at[ seq[i-1]+seq[i] , PAR]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the dataframe by viewing the top 10 rows\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the DataFrame.to_csv() function, save this as a .par file\n",
    "# Note: use sep='\\t'\n",
    "\n",
    "#maindf.to_csv(\"nb06_random-n125_olson1998.par\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -!- STOP\n",
    "# Open the file you just made. Something is off here. \n",
    "# we don't want the values on the left.\n",
    "# We can use booleans with the index keyword to get rid of them\n",
    "\n",
    "#maindf.to_csv(\"nb06_random-n125_olson1998.par\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task:\n",
    "# Using the same rest state, make a .par text file of parameters for the Zechiedrich 336-bp sequence below:\n",
    "# AAACGCGCGAGGCAGCTGTATGGCATGAAAGAGTTCTTCCCGGAAAACGCGGTGGAATATTTCGTTTCCTACTACGACTACTATCAGCCGGAAGCCTATGTACCGAGTTCCGACACTTTCATTGAGAAAGATGCCTCAGCTCTGTTACAGGTCACTAATACCATCTAAGTAGTTGATTCATAGTGACTGCATATGTTGTGTTTTACAGTATTATGTAGTCTGTTTTTTATGCAAAATCTAATTTAATATATTGATATTTATATCATTTTACGTTTCTCGTTCAGCTTTTTTATACTAACTTGAGCGAAACGGGAAGGGTTTTCACCGATATCACCG\n",
    "# save the file as \"zech336_olson1998.par\"\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (4221650302.py, line 19)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[1], line 19\u001b[0;36m\u001b[0m\n\u001b[0;31m    plt.\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Task 2\n",
    "# Plot all non-zero tilt and roll values as a function of base-pair position for the zech336_olson1998 parameters\n",
    "# Make the tilt line green and the roll line orange\n",
    "\n",
    "fig = plt.figure(figsize=(7,3))\n",
    "\n",
    "plt.plot()\n",
    "plt.plot()\n",
    "\n",
    "plt.xlim(1, len(seqdf))\n",
    "plt.ylim(-3, 9)\n",
    "\n",
    "plt.xlabel(\"Base Pair Position\")\n",
    "plt.ylabel(\"degrees\")\n",
    "\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "plt.\n",
    "plt.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Delete example variables\n",
    "\n",
    "del N_seq, seq, stds, maindf\n",
    "\n",
    "\n",
    "# -!- You may delete the \"nb06_random-n125_olson1998.par\" file from your directory\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data Usage and Figure Generation\n",
    "\n",
    "Previously we have worked with the all-atom .pdb files and the parametric .par files\n",
    "\n",
    "In order to make base pair and base-pair steps, we need a set of reference frame data.\n",
    "\n",
    "A refframe frame has 5 lines for every base-pair\n",
    " <li><b>line 1:   the nucleotide base-pair position and sequence</b></li>\n",
    " <li><b>line 2:   the base-pair origin in (x, y, z)</b></li>\n",
    " <li><b>line 3-5: the three unit vectors that describe the orientation of the reference frame</b></li>\n",
    "\n",
    "This is an intermediate task because you first need to go through the file and store only the origin values into a dataframe with x, y, and z column labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules (if not already loaded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load and organize your data\n",
    "\n",
    "infile = open(\"datafiles/test_dnarefframe.dat\",\"r\")\n",
    "data   = infile.readlines()\n",
    "infile.close()\n",
    "\n",
    "# Extract the length of the sequence\n",
    "# --- it is located in the top line, first string of that line\n",
    "# --- we can use the .split(' ') function to turn that line into a space-separated list\n",
    "N_seq = int( data[0].split(' ')[0] )\n",
    "\n",
    "# Remove the header (for reference files it's just the first line) and any \\n new line characters\n",
    "data   = [i.rstrip('\\n') for i in data][1:]\n",
    "\n",
    "data[0:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The origin data is stored in a sequence of lines: For every block of 5 lines it's the 2nd line\n",
    "# Thus, determine the INDEX pattern:\n",
    "# line 1, 6, 11, 16, 21, 26, ... \n",
    "# line [0]*5 + 1 = 1, [1]*5 + 1 = 6, [2]*5 + 1 = 11\n",
    "# so we want every 5*i + 1 line\n",
    "\n",
    "origin_data = []\n",
    "\n",
    "for i in range(0, N_seq):\n",
    "    \n",
    "    origin_data.append( data[ ] )\n",
    "\n",
    "# Finally, split each line based on the whitespace\n",
    "origin_data = [i.split() for i in origin_data]\n",
    "\n",
    "# View the top ten lines using index slicing\n",
    "origin_data[ ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With this list of origin data, we can convert this to a easier to use DataFrame\n",
    "\n",
    "origin_df = pd.DataFrame(data=origin_data, \n",
    "                         columns=['x','y','z'])\n",
    "\n",
    "# We can us an .apply() method to make sure all data in this dataframe is numeric and not objects\n",
    "origin_df = origin_df.apply(pd.to_numeric)\n",
    "\n",
    "# We no longer need to list data\n",
    "del origin_data\n",
    "\n",
    "origin_df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 3-D scatter plot of this dataframe\n",
    "\n",
    "fig = plt.figure(figsize=(7,7))\n",
    "\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "\n",
    "ax._____________________(origin_df.x, origin_df.y, origin_df.z)\n",
    "\n",
    "plt.show()\n",
    "plt.clf()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The 3D plot doesn't seem as helpful. Let's instead look at the 2D projections\n",
    "# Make a 1x3 set of subplots to get a better look at these scatterplots\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(8,3))\n",
    "\n",
    "axes[0].scatter(origin_df.x, origin_df.y)\n",
    "axes[0].set(xlabel=\"x\", ylabel=\"y\")\n",
    "\n",
    "axes[1].scatter(origin_df.x, origin_df.z)\n",
    "axes[1].set(xlabel=\"x\", ylabel=\"z\")\n",
    "\n",
    "axes[2].scatter(origin_df.y, origin_df.z)\n",
    "axes[2].set(xlabel=\"y\", ylabel=\"z\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.clf()\n",
    "\n",
    "\n",
    "# The images along with the 3D plot show a string that either comes out or goes into a supercoiled region, \n",
    "# similar to the '1KX5' model we used in a previous assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having these 3D positions allows one to calculate, visualize, and understand relationships.\n",
    "\n",
    "One such example would be to see how far each base-pair origin is from the other points. For a chain of 200 base pairs, we would need to determine the distance of every base relative to any other one. \n",
    "\n",
    "Recall that the distance formula is:\n",
    "$$\\sqrt{(x_2 - x_1)^2 + (y_2 - y_1)^2 + (z_2 - z_1)^2}$$\n",
    "\n",
    "This means applying that formula 40,000 times.\n",
    "\n",
    "We can use a function in the `scipy` package, spatial.distance, that would make it easier to calculate this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance \n",
    "\n",
    "# In this is a function: pdist()\n",
    "\n",
    "# Look up information on pdist() here: https://docs.scipy.org/doc/scipy/reference/spatial.distance.html\n",
    "\n",
    "# Calculate the pdist of the reference frame origins and then create a heatmap plot\n",
    "distances = distance.pdist(origin_df)\n",
    "\n",
    "print(distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The 'distances' container we made is 19900 entries long. But we wanted something that was 200x200.\n",
    "# There's another function, .squareform() that does just that\n",
    "\n",
    "distances = distance.squareform(distances)\n",
    "\n",
    "print(distances) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once the data is in a square form, we can use plt.imshow() to make a 2D heatmap\n",
    "\n",
    "fig = plt.figure(figsize=(5,5))\n",
    "\n",
    "plt.imshow(distances, \n",
    "           # We can move the origin point from the default \"upper\" to \"lower\"\n",
    "           origin=\"lower\"\n",
    "          )\n",
    "\n",
    "plt.show()\n",
    "plt.clf()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As with any figure, we can customize the colors. However for imshow(), we will need colormaps\n",
    "# Check this out: https://matplotlib.org/stable/tutorials/colors/colormaps.html\n",
    "# We should use a diverging colormap so that white regions are closest to the mean\n",
    "\n",
    "fig = plt.figure(figsize=(5,5))\n",
    "\n",
    "plt.imshow(distances, \n",
    "           origin=\"lower\", \n",
    "           # Use a blue-white-red cmap such that red is upper limit and blue lower limit\n",
    "           cmap='bwr'\n",
    "          )\n",
    "# We will need to see what the colors mean, so we need a colorbar\n",
    "plt.colorbar(shrink=0.50)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets try one last plot. We will use the 'gnuplot' colormap \n",
    "# but this time we will normalize the data \n",
    "\n",
    "fig = plt.figure(figsize=(5,5))\n",
    "\n",
    "plt.imshow(distances, \n",
    "           origin=\"lower\", \n",
    "           norm='linear',\n",
    "           cmap='gnuplot'\n",
    "          )\n",
    "plt.colorbar(shrink=0.50)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del origin_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Distribution, statistics, and plotting with `seaborn`\n",
    "\n",
    "Molecular model data offers great details, but if one were to make over 10,000 models, there needs to be ways to visualize large swaths of data.\n",
    "\n",
    "Seaborn organizes its modules as either:\n",
    "\n",
    "| __relplot__ | __displot__ | __catplot__ |\n",
    "|:-------------:|:-------------:|:-------------:|\n",
    "| _relational_ | _distributions_ | _categorical_ |\n",
    "| scatterplot | histplot | stripplot |\n",
    "| lineplot | kdeplot | swarmplot |\n",
    "| | ecdfplot | boxplot |\n",
    "| | rugplot | violinplot |\n",
    "| | | pointplot |\n",
    "| | | barplot |\n",
    "\n",
    "\n",
    "A common use of Seaborn is to make __distribution__ plots. Let's look at the distribution of some results data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"datafiles/test_resultsdata\", skiprows=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are 24576 x 18 data entries in this file. We may want to plot everything, or want to work with a select set of data.\n",
    "# Pandas has a method for selecting data using logic operators \n",
    "\n",
    "# For example, if I only want to see data where the \"insert_label\" is \"h\" and \"opt_type\" is \"dim2022\", I can select those in square brackets\n",
    "\n",
    "df[ (df.insert_label==\"h\")\n",
    "    &(df.opt_type==\"dim2022\") ]\n",
    "\n",
    "# This \"shrinks\" the dataframe to 4096 x 18 and does not delete any of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: How many entries use both an 'AAAAAA' insert_seq and nmer_seq?\n",
    "\n",
    "df[ (df.) & (df.) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: How many entries with the \"hnat\" insert_label has a kinking angle at the 5-prime end (labeled phi_kink5) greater than 1.95?\n",
    "\n",
    "df[  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can make copies of DataFrames from these selections as a way to make analysis easier.\n",
    "# Here we will make a plotting dataframe called plotdf that is a copy of the original\n",
    "# selecting only the \"tet2022\" opt_type data\n",
    "# Once it has been copied we will reset in the index numbering, making sure to say drop=True so we do not make a new column with the old index values\n",
    "plotdf = df.copy()\n",
    "plotdf = plotdf[ (plotdf.opt_type==) ]\n",
    "plotdf = plotdf.reset_index(drop=True)\n",
    "plotdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This can also be written in a single line:\n",
    "\n",
    "plotdf2 = df[ (df.opt_type==\"tet2022\") ].copy().reset_index(drop=True)\n",
    "plotdf2.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotdf == plotdf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del plotdf2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using these selection methods are great prior to plotting.\n",
    "\n",
    "However, packages like `seaborn` allow selecting from within their plot functions.\n",
    "\n",
    "Take for instance a distribution plot (`sns.displot()`) of only 'e_opt' data in the plotdf dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(5,3))\n",
    "\n",
    "sns.displot(data = plotdf,\n",
    "            x = \"e_opt\")\n",
    "\n",
    "plt.show()\n",
    "plt.clf()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The above plot is for all data in the dataframe. But we know from earlier that there are different types of data, such as \"opt_type\" and \"insert_types\"\n",
    "# We can select within the .displot() using \"hue\": we can make multiple distributions of different colors seperated by \"insert_label\"\n",
    "\n",
    "fig = plt.figure(figsize=(5,3))\n",
    "\n",
    "sns.displot(plotdf, x='e_opt', \n",
    "            hue=              )\n",
    "\n",
    "plt.show()\n",
    "plt.clf()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can separate these even more by using the 'col' keyword which makes columns of plots based on yet another selection\n",
    "\n",
    "# This time we will go back to the original dataframe, df, and make distribution plots with columns based on \"opt_type\"\n",
    "\n",
    "fig = plt.figure(figsize=(6,3))\n",
    "\n",
    "sns.displot(df, \n",
    "            x='e_opt', \n",
    "            hue=\"insert_label\", \n",
    "            col=    )\n",
    "\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Well that's interesting. In use of whatever \"tet2022\" means, we have a wider swath of \"e_opt\" values than with the \"dim2022\" opt_type.\n",
    "# Let's go deeper.\n",
    "\n",
    "# Let's make a scatter plot of two columns-'e_optroll' and 'e_opttwist'- of a dataframe where we keep only 'h' insert_label data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf = df[ (df.insert_label==\"h\") ].reset_index(drop=True)\n",
    "\n",
    "fig = plt.figure(figsize=(3,3))\n",
    "\n",
    "sns.scatterplot(newdf, \n",
    "                x='e_optroll',\n",
    "                y='e_opttwist',\n",
    "                hue=\"opt_type\",\n",
    "               alpha=0.25, edgecolor='black')\n",
    "\n",
    "plt.show()\n",
    "plt.clf()\n",
    "del newdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A great tool within seaborn is a .jointplot(), which can combine distributions with scatters\n",
    "\n",
    "newdf = df[ (df.insert_label==\"h\") ].reset_index(drop=True)\n",
    "\n",
    "fig = plt.figure(figsize=(3,3))\n",
    "\n",
    "sns.jointplot(newdf, \n",
    "              x=,\n",
    "              y=,\n",
    "              hue=\"opt_type\",\n",
    "              alpha=0.25, edgecolor='black')\n",
    "\n",
    "plt.show()\n",
    "plt.clf()\n",
    "del newdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task:\n",
    "# Make a df based on the \"tet2022\" opt_type and keep data where the e_opt values are less than the median e_opt.\n",
    "# Plot 'e_optroll' and 'e_opttwist' and split the hue by insert_seq\n",
    "\n",
    "newdf = df[  ].reset_index(drop=True)\n",
    "\n",
    "fig = plt.figure(figsize=(3,3))\n",
    "\n",
    "sns.jointplot(newdf, \n",
    "              x=,\n",
    "              y=,\n",
    "              hue=,\n",
    "              alpha=0.25, edgecolor='black')\n",
    "\n",
    "plt.show()\n",
    "plt.clf()\n",
    "del newdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I was to see all of the parametric energy relationships with the \"tet2022\" data, hence the pairplot function\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "newdf = df[ (df.opt_type==\"tet2022\") ].reset_index(drop=True)\n",
    "\n",
    "sns.pairplot(newdf,\n",
    "             vars=[\"e_opt\"+par for par in ['tilt','roll','twist','shift','slide','rise']],\n",
    "             hue=\"insert_label\")\n",
    "\n",
    "del newdf\n",
    "plt.savefig(\"test_results_tet2022_pairplot.png\", dpi=300)\n",
    "\n",
    "plt.show()\n",
    "plt.clf()\n",
    "\n",
    "# This will produce a large 6X6 plot where the diagonals are the distributions of that data and off-diagonals are scatterplots between two parameters\n",
    "# example: Row #3 y-axis is \"e_opttwist\", so in index [2,2] you will see the distribution of e_opttwist data. \n",
    "# Everything else in the row are scatterplots based on the x-axis labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dr. Robert Young, University of Maryland\n",
    "# In collaboration with Matthew Osborne, Erdos Institute\n",
    "# UMD FIRE Genome Computing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
