{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b65b1711-38c7-4771-94f3-8d4fc2bfec18",
   "metadata": {},
   "source": [
    "# UMD FIRE Stream- Genome Computing IV\n",
    "## Basic Statistics & Using the `pandas` Package\n",
    "\n",
    "In this notebook we will learn:\n",
    "<ul>\n",
    "    <li>what a common python data handling package is</li> \n",
    "    <li>the basic pandas data structures</li> \n",
    "    <li>useful pandas dataframe funtionality</li> \n",
    "    <li>subsetting/searching a pandas dataframe</li> \n",
    "    <li>getting pandas to generate descriptive statistics</li> \n",
    "    <li>using pandas to read in data</li>\n",
    "    <li>using pandas to save data</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419c72e7-90dc-4c77-955e-eecf80156552",
   "metadata": {
    "tags": []
   },
   "source": [
    "# `pandas`\n",
    "\n",
    "`pandas` is one of the most popular data handling packages in `python`. We'll go over the minimum you'll need to know about the package in this notebook.\n",
    "\n",
    "Let's start by importing the package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7733a31d-3bce-48c3-98c2-43e8a9f89985",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is standard practice to import pandas as pd\n",
    "import pandas as pd\n",
    "\n",
    "# We will also import the numerical python package, numpy\n",
    "import numpy as np\n",
    "\n",
    "# We can refer to the pandas and numpy documentation regularly for methods, functions, and syntax questions\n",
    "# pd- https://pandas.pydata.org/docs/user_guide/index.html#user-guide\n",
    "# np- https://numpy.org/doc/1.24/user/index.html#user\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd9c902-783a-45b3-a11a-856ee55680f2",
   "metadata": {},
   "source": [
    "### Series and Dataframes\n",
    "\n",
    "`pandas` has two main data structures:\n",
    "`Series` objects \n",
    "`DataFrame` objects. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea224496-8176-4b92-949e-cd5476f3af93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can turn a list into a series with pd.Series()\n",
    "\n",
    "print([0,1,2,3], type([0,1,2,3]))\n",
    "print()\n",
    "print(pd.Series([0,1,2,3]), type(pd.Series([0,1,2,3])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a2342f-967f-40ad-9061-c5331146bdc4",
   "metadata": {},
   "source": [
    "The second thing we printed was a `Series` object. \n",
    "\n",
    "Note the two columns of numbers. \n",
    "\n",
    "The first column is the index of the object, the second column contains the values of the object. We can access those two separately like below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c828f01-fae6-4146-973d-27767412d49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The index\n",
    "\n",
    "pd.Series([0,1,2,3]).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e2255f-cc87-4818-91d4-aa33cd227443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The values\n",
    "\n",
    "pd.Series([0,1,2,3]).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77207f9a-a9ac-479c-bcaf-72ed5e152879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the array labeled a and turn it into a Series named b\n",
    "\n",
    "a = [5,2,3,6,'a','b','e',True,False]\n",
    "\n",
    "\n",
    "\n",
    "b = pd.Series(a)\n",
    "b\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032009ce-c4f3-4cc0-8b5f-dacb4e28d530",
   "metadata": {},
   "source": [
    "Now let's check out a `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98aa766a-48a5-40c6-a90a-fdbeab750c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can make a DataFrame using a dictionary with the dictionary keys as column labels and the dictionary values are columns\n",
    "\n",
    "df = pd.DataFrame({'one':[3,4,5,2,4,5], \n",
    "                   'two':['a','b','e','h','l','p']})\n",
    "\n",
    "# Note that this is not the only way to make a dataframe!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17888a7-0417-4320-aad6-3f760585c977",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f7b465-5e3d-4b3d-b37c-bdcf7f42564f",
   "metadata": {},
   "source": [
    "This is a `DataFrame`, the unlabeled column is the index, the labeled columns are `Series` objects themselves.\n",
    "\n",
    "We can access them in the following way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3dc0dca-300c-415e-9dd6-c78e5de4f0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[4:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad7708d-26cc-4dd2-8824-5d56f41e7684",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.at[1, 'two']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c16198d-4c06-46f1-b966-cd2eae8b60c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iat[1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19951017-728e-4998-b630-018f21dd873f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.column_name\n",
    "print(df.one) \n",
    "print()\n",
    "print(type(df.one))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9ca9c9-6df5-4340-9161-91f1f3ee977e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# or df['column_name']\n",
    "print(df['two']) \n",
    "print()\n",
    "print(type(df['two']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb38f504-20ad-474d-9ec3-7e082f11d2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just like with series we can use .index\n",
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddcfa324-3107-41c7-a94e-2927fa357ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Practice\n",
    "# Make a data frame with the first column labeled 'first' from list a and the second column labeled 'second' from list b\n",
    "# Next, see what happens when you add index=range(10,10+len(a)) after the dictionary\n",
    "\n",
    "a = [4,5,3,4,5,6,0]\n",
    "\n",
    "b = ['a','c','d','g','l','m','p']\n",
    "\n",
    "\n",
    "df2a = pd.DataFrame({'first':a, 'second':b})\n",
    "\n",
    "df2b = pd.DataFrame({'first':a, 'second':b}, index=range(10, 10+len(a)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da6b6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7e5352",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb43694",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df2a, df2b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ac9944-2a4b-4433-98b5-0e15501a62cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What if our list contains numerous separations?\n",
    "a = [\"a c f g    s q   q  r   h h  v\"]\n",
    "\n",
    "# we can use the function .split() on the element in the list to turn THAT into a list (now a \"list of lists\")\n",
    "\n",
    "A = a[0].split()\n",
    "\n",
    "print(a)\n",
    "print()\n",
    "print(A)\n",
    "\n",
    "print('-'*10)\n",
    "\n",
    "print(a[0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77fbbd2f-c6d4-4f03-9e51-f38d7ea447a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ec8aba-3960-4a09-bc2f-df89c7e6c25d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "de2a6e19-0dbb-4a62-b436-5136e4d75130",
   "metadata": {},
   "source": [
    "### Helpful `DataFrame` Functions\n",
    "\n",
    "`pandas` offers some really nice built in function to help you explore any data set you're dealing with. Let's explore them below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd81a9a-c3aa-4a67-a194-584373ae23a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll work with the following dataframe\n",
    "\n",
    "df = pd.read_table(\"datafiles/test_dnapar.par\", \n",
    "                   skiprows=2, # we need to exclude the header\n",
    "                   sep='\\s+' # the columns in the par file as separated by multiple spaces of differing lengths\n",
    "                  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e574f3-d91f-49a4-9515-eb51f48e4997",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[31]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f515fa67-2710-47c6-a379-6f46e237e7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can examine the top of the dataframe, the default is the first 5 entries\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ac2c3f-9a8e-4084-9bc5-cacb91b18390",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also look at the bottom\n",
    "# Plus, we can put in a number lets us control the number of rows\n",
    "\n",
    "df.tail(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56713503-4ee0-4d5b-869c-fd4da10de29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can get a random sample\n",
    "\n",
    "df.sample(20)\n",
    "\n",
    "# Look to the indices for proof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845a1067-72d7-4732-8f63-4cc443c87c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## We can sort our dataframe by a single column\n",
    "\n",
    "df.sort_values('#')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a443021-752a-433d-b8ec-b4024f61bac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... or by multiple columns\n",
    "# And can choose to go in descending order\n",
    "\n",
    "df.sort_values(['#','Twist'],\n",
    "               ascending=[True,False])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e81dd0-7211-4ffa-bd4f-902be5af0691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can drop certain values by index\n",
    "\n",
    "df.drop([0,1,2,3]).head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d663932-6912-486f-9e2f-4868da1595c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: if you have missing data you can drop it too\n",
    "\n",
    "df.dropna()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5330ad33-9122-4350-85db-0d96fad8e1e5",
   "metadata": {},
   "source": [
    "### Getting Descriptive Statistics\n",
    "\n",
    "`pandas` has more built in functions that will allow you to calculate some descriptive statistics that could be useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29e1228-fe56-4f1f-9607-7a061004dd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the max for each column\n",
    "\n",
    "df.max()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fd0057-b45f-498d-8936-9697620703b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also find the maximum or minimum value for a specific column\n",
    "# This can be done using [''] notatiton if the header name has spaces,\n",
    "\n",
    "df['Prop-Tw'].max()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6570b753-e745-4309-acef-0fc03954aef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... or the header name can be separately by a period\n",
    "\n",
    "df.Buckle.max()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79852e8-1e39-47ae-a45c-a423a82af17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In added to max and min, we can find the mean (or average)\n",
    "\n",
    "# Let's try manually first\n",
    "# Take the sum of all Stagger values and divide by the number of entries\n",
    "\n",
    "print ( df.Stagger.sum() / len( df.Stagger ) )\n",
    "\n",
    "# Or you can use the .mean() function built in\n",
    "print( df.Stagger.mean() )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5091d7-109f-4508-ad5b-a5f7a01f6a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can get a count of how many of each value exist in a column\n",
    "\n",
    "df['#'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a021fdb8-8b55-4e67-9efb-013deb1497c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can determine the middle value of a set of data- the median\n",
    "# The most repeated value- the mode\n",
    "# and compare them to the mean\n",
    "\n",
    "print( df.Rise.median() )\n",
    "print( df.Rise.mode() )\n",
    "print( df.Rise.mean() )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f21d301-00c8-448b-8c98-3ab7bd655058",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of summary stats\n",
    "\n",
    "df.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a3c6ad-ca23-41f5-8233-a0ed738e7202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If .describe() isn't helpful, we can use df.agg() with a list of statistics we want to see for all columns\n",
    "# NOTE: be careful with .agg() as it will not cooperate with text data\n",
    "\n",
    "df.drop(columns=['#']).agg(['median','mean','min','max','sum'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5efe7e-fcc5-48f2-8acd-df993d5ec9b0",
   "metadata": {},
   "source": [
    "In addition to mean, median, and mode, we can collect distribution-based statistics.\n",
    "\n",
    "This includes: variance (.var()) and standard deviation (.std() )\n",
    "<ul>\n",
    "<li> Variance is a measure of data dispersion, or the spread, and is the mean-squared difference between each data point to the mean value</li>\n",
    "<li> Standard Deviation (the square root of the variance) is a measure of dispersion related to a normal distribution of the data</li>\n",
    "    </ul>\n",
    "\n",
    "We can also determine relationships between parameters using covariance (.cov()) and correlation (.corr())\n",
    "<ul>\n",
    "<li> Covariance is the measure of how two random variable will change with respect to each other. It's calculated as the average of the product of the variance of the two parameters</li>\n",
    "<li> Correlation is similar in definition to covariance and is calculated by dividing the covariance of the parameters by the product of both parameterss standard deviations</li>\n",
    "    </ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d47cb6-d580-4279-9809-a37a196a2193",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.Opening.var())\n",
    "print()\n",
    "print(df.Opening.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e2a607-3aaa-4781-876a-dbf5388cf193",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Tilt','Roll','Twist']].cov()\n",
    "\n",
    "# Note: for this covariance matrix, the diagonal terms are the variance values of the parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2a06d4-d06d-493d-8fdc-42a4b479924a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Tilt','Roll','Twist']].corr()\n",
    "\n",
    "# From \"Correlation cofficient\" on wikipedia:\n",
    "# \"Several types of correlation coefficient exist, each with their own definition and own range of usability and characteristics. \n",
    "# They all assume values in the range from −1 to +1, where ±1 indicates the strongest possible agreement and 0 the strongest possible disagreement.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aee0383-79b7-44e2-bd29-bbb6cf94e148",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Subsetting and Searching a `DataFrame`\n",
    "\n",
    "Recall from the web 3DNA Tutorials that for base pair parameters the first row can be non-zero values, yet base-pair STEP parameters must have be null values in this row? This messes up the statistics for the base-pair step parameters. \n",
    "\n",
    "Sometimes we'll want to get a subset of a `DataFrame` or search for observations that fit a certain condition. There are a few ways we can do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5dcdbde-3b38-4a1b-9ed0-5bfa436c2f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf8d8f7-c50b-4762-a15f-c133ff12c91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# .loc for logical subsetting\n",
    "# First enter the boolean condition you're interested in\n",
    "# Then, if you want certain columns you can enter that after the comma\n",
    "\n",
    "df.loc[ df.Twist > 0.000 , ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13dcefbe-9e93-4a93-be1f-a7296868ab36",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Tilt','Roll','Twist','Shift','Slide','Rise']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f154a6-c2b5-47da-bf12-622abb0b0a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[ df.Twist > 0.000 , ][['Tilt','Roll','Twist','Shift','Slide','Rise']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b375331-f4e9-4504-baac-5b31dada44e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's sort based on multiple conditions\n",
    "\n",
    "df.loc[(df.Roll > 10) & (df.Slide > 0), ['Tilt','Roll','Twist']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c890eb1e-374b-487a-80c3-fb6809547ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset with a numeric index use iloc, first rows then columns\n",
    "# Get rows 14 through 23\n",
    "\n",
    "df.iloc[14:23, ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74aea09e-5de2-40f8-8947-87c2598800e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[14:23, 10:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18453ca0-2618-4643-a0c5-1d37a9c4a2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can even groupby for categorical variables to make calculating summary stats easier\n",
    "\n",
    "df.groupby('#').median()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b05b574",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task\n",
    "# Load the test_dnapdb.pdb file into a list, removing all newline characters\n",
    "# Remove the head and any item that starts with CONECT\n",
    "# Load remaining list into a dataframe,\n",
    "# Study this url (https://www.cgl.ucsf.edu/chimera/docs/UsersGuide/tutorials/framepdbintro.html) to determine what the column headers should be for a pdb file and then add that to the dataframe\n",
    "# How many atom types are in this structure? How many of each nucleotide is in here? How many base pairs?\n",
    "# What is the average x, y, and z coordinates for P atoms in Chain A?\n",
    "\n",
    "\n",
    "infile = open(\"datafiles/test_dnapdb.pdb\", \"r\")\n",
    "indata = infile.readlines()\n",
    "infile.close()\n",
    "\n",
    "# First, get rid of newline characters\n",
    "indata = [i.rstrip('\\n') for i in indata]\n",
    "\n",
    "# Only keep ATOM record data\n",
    "indata = [i for i in indata if i.startswith(\"ATOM \")]\n",
    "\n",
    "# Use .split() to split each row based on whitespace\n",
    "indata = [i.split() for i in indata]\n",
    "\n",
    "# Load list-of-lists 'indata' variable into DataFrame\n",
    "pdb_df = pd.DataFrame(indata,\n",
    "                     columns=[\"RECORD\",\"atom_number\",\"atom_name\",\"residue_name\",\"chain_id\",\"residue_seq_number\",\"x\",\"y\",\"z\",\"occupancy\",\"temp_factor\",\"element_symbol\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523dc708-5479-4e25-91e6-2099eb87dc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since this is coming from a data file, make sure your atom_number, residue_seq_number, x, y, z, occupancy, and temp_factor are numeric data types\n",
    "numeric_data_types = {'atom_number':int, \n",
    "                      'residue_seq_number':int,\n",
    "                      'x':float, \n",
    "                      'y':float,\n",
    "                      'z':float, \n",
    "                      'occupancy':float,\n",
    "                      'temp_factor':float }\n",
    "pdb_df = pdb_df.astype(numeric_data_types)\n",
    "pdb_df.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fbd996a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For number of atom types, you want to know all unique atom_name occurances\n",
    "# select the atom_name column and use .unique()\n",
    "# ... and use len to count\n",
    "\n",
    "len( pdb_df.atom_name.unique() )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fcc3ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the nucleotide count, recall that each nucleotide must have one phosphate, so select data with only P atom_names\n",
    "# The use .value_counts() on the resident_name column\n",
    "\n",
    "pdb_df[pdb_df.atom_name == \"P\"].residue_name.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae10f535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the same selection of the phosphate atoms but this time just count how many are in chain A or chain B\n",
    "\n",
    "pdb_df[pdb_df.atom_name == \"P\"].chain_id.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ab0d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"mean of x: \", pdb_df[(pdb_df.atom_name == \"P\")&(pdb_df.chain_id == \"A\")].x.mean() )\n",
    "\n",
    "print(\"mean of y: \", pdb_df[(pdb_df.atom_name == \"P\")&(pdb_df.chain_id == \"A\")].y.mean() )\n",
    "\n",
    "print(\"mean of z: \", pdb_df[(pdb_df.atom_name == \"P\")&(pdb_df.chain_id == \"A\")].z.mean() )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afec4226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dr. Robert Young, University of Maryland\n",
    "# In collaboration with Matthew Osborne, Erdos Institute\n",
    "# UMD FIRE Genome Computing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
